{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmenter\n",
    "import importlib\n",
    "importlib.reload(segmenter)\n",
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import yaml\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "# from unet import UNet\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "from skimage import io, morphology, color\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology  import remove_small_objects\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.color import label2rgb\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet18\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=2,                      # model output channels (number of classes in your dataset)\n",
    ")\n",
    "\n",
    "model_path = '/home/ssawmya-local/FM_work/Notebooks_and_files/checkpoint_50ns/resnet18.pth'\n",
    "weights = torch.load(model_path)\n",
    "model.load_state_dict(weights)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/storage/tommy-local/em-vis/ems_uint8_04_25\"\n",
    "files = glob.glob(image_path + \"/*.png\")\n",
    "\n",
    "# find files that have \"00050ns\" in them\n",
    "files = [f for f in files if \"00050ns\" in f]\n",
    "images = []\n",
    "for f in files:\n",
    "    images.append(cv.imread(f, cv.IMREAD_GRAYSCALE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyvoi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpyvoi\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyvoi'"
     ]
    }
   ],
   "source": [
    "import pyvoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverting the image as not using custom watershed function\n"
     ]
    }
   ],
   "source": [
    "# example of how to use the segmenter\n",
    "model_path = '/home/ssawmya-local/FM_work/Notebooks_and_files/checkpoint_50ns/resnet18.pth'\n",
    "Iseg = segmenter.Segmenter(model_path, segmenter_function = measure.label)\n",
    "Iseg.set_model(model_class=model)\n",
    "labels = Iseg.get_labels(images[0])\n",
    "\n",
    "# plt.imshow(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of how to use segmenter with watershed segmentation\n",
    "from utils import watershed\n",
    "Iseg = segmenter.Segmenter(model_path, segmenter_function = watershed)\n",
    "Iseg.set_model(model_class=model)\n",
    "labels = Iseg.get_labels(images[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dasparsity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
